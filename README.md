# Tennis Match Outcome Prediction Pipeline

This repository implements a full end-to-end pipeline to predict tennis match outcomes using historical match data, player metadata, and rankings.

## Project structure

```
scripts/               # Step-by-step data processing, modeling, and evaluation scripts
data/processed/        # Intermediate and final datasets, best parameters, model artifacts
reports/               # Evaluation plots (calibration, reliability diagrams)
database.sqlite        # Raw SQLite database with matches, players, rankings tables
data_dictionary.txt    # Column definitions for the raw tables
README.md              # This overview and usage instructions
```

## Pipeline steps

1. **Data extraction** (`01_data_extraction.py`): Inspect raw tables
2. **Data cleaning & joining** (`02_data_cleaning_joining.py`): Convert dates, merge player metadata
3. **Labeling & framing** (`03_label_framing.py`): Define train examples (player1 vs player2)
4. **Feature engineering** (`04_feature_engineering.py`): ELO ratings, surface win-rates, head-to-head, diffs
5. **Baseline modeling** (`05_train_baseline.py`): Logistic regression baseline evaluation
6. **Advanced models** (`06_advanced_models.py`): RandomForest, XGBoost, LightGBM evaluation
7. **Hyperparameter tuning** (`07_hyperparameter_tuning.py`): Randomized search for best params
8. **Final evaluation & calibration** (`08_final_evaluation.py`): Calibration curves and metrics
9. **Deployment & model export** (`09_deployment.py`): Train final models and serialize artifacts

## Deployment & usage

After running all prior steps (1â€“8), execute the deployment script to train on the full dataset and save the final models:

```bash
python scripts/09_deployment.py
```

This will write serialized model files to `data/processed/`:

- `lightgbm_final.joblib` or `.pkl`
- `xgboost_final.joblib` or `.pkl`

### Loading a trained model for inference

```python
import pickle
from pathlib import Path

# adjust extension if using joblib
model_path = Path('data/processed/lightgbm_final.joblib')
if not model_path.exists():
    model_path = model_path.with_suffix('.pkl')

with open(model_path, 'rb') as f:
    model = pickle.load(f)

# `df_features` must be a DataFrame with the same feature columns used for training:
# ['elo_diff','elo_surf_diff','age_diff','ht_diff','rank_diff',
#  'rank_points_diff','surf_win_rate_diff','player1_h2h_win_rate','h2h_count']
proba = model.predict_proba(df_features)[:, 1]
```

### Raw-to-inference workflow

To retrace the full preprocessing and modeling pipeline from raw data through prediction:

```bash
python scripts/01_data_extraction.py
python scripts/02_data_cleaning_joining.py
python scripts/03_label_framing.py
python scripts/04_feature_engineering.py
python scripts/09_deployment.py
```

## Next steps

- Monitor model performance over time (data drift, calibration drift)
- Integrate live ELO updates for streaming match predictions
- Expose an API or batch scoring endpoint for real-time inference

---
*Generated by the ML pipeline scripts.*